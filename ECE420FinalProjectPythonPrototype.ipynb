{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XG11/ECE420FinalProject/blob/main/ECE420FinalProjectPythonPrototype.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXd1AmSkqtqA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.ndimage import gaussian_filter, gaussian_gradient_magnitude\n",
        "from scipy.spatial.distance import euclidean\n",
        "from scipy.signal import convolve2d\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#applies gaussian kernel in spacial domain to image using sigma blur operator to generate blurred image in each scale\n",
        "def BlurredImage(image, sigma):\n",
        "  gaussian = np.zeros((image.shape[0], image.shape[1]))\n",
        "  for i in range(0, image.shape[0]):\n",
        "    for j in range(0, image.shape[1]):\n",
        "      gaussian[i][j] = 1/(2 * np.pi * sigma * sigma) * np.exp(-1 * (np.square(i) + np.square(j))/(2 * np.square(sigma)))\n",
        "  L = convolve2d(image, gaussian, mode='same')\n",
        "  return L\n",
        "\n",
        "#takes in image, sigma, number of scales, and number of octaves\n",
        "#returns a list of lists with each list containing images with different scales and each list representing octave\n",
        "def octaves(image, sigma, scale, octave):\n",
        "  l_images = []\n",
        "  num_octave = []\n",
        "  im_copy = image.copy()\n",
        "  for o in range(0, octave):\n",
        "    if(o != 0):\n",
        "      im_copy = cv2.resize(im_copy, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_LINEAR)\n",
        "    r_image = im_copy.copy()\n",
        "    for s in range(0, scale):\n",
        "       r_image = BlurredImage(r_image, sigma)\n",
        "       num_octave.append(r_image)\n",
        "    l_images.append(num_octave)\n",
        "    for s in range(0, scale):\n",
        "      num_octave.pop()\n",
        "  return l_images\n",
        "\n",
        "#returns difference of gaussian images within each octave, need to call previous octave function to input into this\n",
        "def DOG(l_images):\n",
        "  d_images = []\n",
        "  num_octave = []\n",
        "  for i in range(0, len(l_images))\n",
        "    for j in range(0, len(l_images[i]) - 1):\n",
        "      difference = l_images[i][j+1] - l_images[i][j]\n",
        "      num_octave.append(difference)\n",
        "    d_images.append(num_octave)\n",
        "    num_octave.clear()\n",
        "  return d_images\n",
        "\n",
        "\n",
        "l_images = octaves(image, 1, 5, 4) #sigma = 1, scale = 5, octave = 4\n",
        "d_images = DOG(l_images) #get difference of gaussians"
      ],
      "metadata": {
        "id": "eKQBalNP6jFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this function returns all keypoints taking in the difference of gaussians\n",
        "def keypoints(d_images, threshold = 0.3):\n",
        "  keypoints = []\n",
        "  scale_factor = 2\n",
        "  for o, octave in enumerate(d_images):\n",
        "    for s, scale in octave:\n",
        "      current = scale\n",
        "      prev = octave[s - 1] if s > 0 else None  # Previous scale (handle the first scale)\n",
        "      next = octave[s + 1] if s < len(octave) - 1 else None  # Next scale (handle the last scale)\n",
        "      for i in range(1, current.shape[0] - 1):\n",
        "        for j in range(1, current.shape[1] - 1):\n",
        "          current_pixel = current[i][j]\n",
        "          if abs(current_pixel) < threshold:\n",
        "            continue\n",
        "\n",
        "          neighborhood = [prev[i-1:i+2, j-1:j+2], current[i-1:i+2, j-1:j+2], next[i-1:i+2, j-1:j+2]] if prev is not None and next is not None else []\n",
        "          max_val = np.max(neighborhood)\n",
        "          min_val = np.min(neighborhood)\n",
        "          if current_pixel == max_val or current_pixel == min_val:\n",
        "            original_i = i * (scale_factor ** (o + 1))\n",
        "            original_j = j * (scale_factor ** (o + 1))\n",
        "            keypoints.append([o, s, original_i, original_j])\n",
        "\n",
        "  return keypoints\n",
        "\n",
        "keypoint_result = keypoints(d_images, threshold = 0.3) #get keypoint results"
      ],
      "metadata": {
        "id": "5CQ2JVM2bgOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#do gradient calculations for neighborhood around image based on scale(sigma level of blurring in particular image\n",
        "#does calculation of gradients for one keypoint, must be called with each keypoint\n",
        "def M_theta_calculation(image, keypoint):\n",
        "    x, y = keypoint[2], keypoint[3]\n",
        "    scale = keypoint[1]\n",
        "    if(scale > 2):\n",
        "      radius = 16\n",
        "    else:\n",
        "      radius = 8\n",
        "    gradient_magnitudes = []\n",
        "    gradient_orientations = []\n",
        "\n",
        "    # Compute gradient magnitudes and orientations around the keypoint\n",
        "    for i in range(-radius, radius + 1):\n",
        "        for j in range(-radius, radius + 1):\n",
        "            if (0 < x + i < image.shape[0] - 1) and (0 < y + j < image.shape[1] - 1):\n",
        "                dx = image[x + i, y + j + 1] - image[x + i, y + j - 1]\n",
        "                dy = image[x + i + 1, y + j] - image[x + i - 1, y + j]\n",
        "                magnitude = np.sqrt(dx**2 + dy**2)\n",
        "                orientation = np.degrees(np.arctan2(dy, dx)) % 360\n",
        "                gradient_magnitudes.append(magnitude)\n",
        "                gradient_orientations.append(orientation)\n",
        "    return gradient_magnitudes, gradient_orientations\n",
        "\n",
        "#creates histogram based on bin size and returns it and the dominant orientation\n",
        "def histogram(gradient_magnitudes, gradient_orientations, bin_size):\n",
        "   orientation_histogram = np.zeros(bin_size)\n",
        "   for magnitude, orientation in zip(gradient_magnitudes, gradient_orientations):\n",
        "     if(orientation == 360):\n",
        "       bin_index = 0\n",
        "     else:\n",
        "       bin_index = int(orientation // (360 // bin_size))\n",
        "     orientation_histogram[bin_index] += magnitude\n",
        "   dominant_orientation = np.argmax(orientation_histogram) * (360 // bin_size)\n",
        "   return(orientation_histogram, dominant_orientation)"
      ],
      "metadata": {
        "id": "NJVll2S2xBfq",
        "outputId": "d8cca933-1bae-47fa-bee7-7e75a420165c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-1-267be712619f>, line 6)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-267be712619f>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    x, y = keypoint[2], keypoint[3]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient(image, x, y):\n",
        "    \"\"\"\n",
        "    Compute gradient magnitude and orientation at pixel (x, y) using central difference.\n",
        "    \"\"\"\n",
        "    dx = image[x, y + 1] - image[x, y - 1]  # Central difference in the x direction\n",
        "    dy = image[x + 1, y] - image[x - 1, y]  # Central difference in the y direction\n",
        "\n",
        "    magnitude = np.sqrt(dx**2 + dy**2)  # Gradient magnitude\n",
        "    orientation = np.degrees(np.arctan2(dy, dx)) % 360  # Gradient orientation (0 to 360 degrees)\n",
        "\n",
        "    return magnitude, orientation\n",
        "\n",
        "def compute_keypoint_descriptor(image, keypoint, dominant_orientation):\n",
        "    \"\"\"\n",
        "    Compute the descriptor for the keypoint in the image.\n",
        "    \"\"\"\n",
        "    # Extract a scaled window around the keypoint (taking scale into account)\n",
        "    #scaled_window = extract_scaled_patch(image, keypoint, window_size)\n",
        "\n",
        "    # Compute gradients and orientations\n",
        "    #gx, gy = compute_gradients(scaled_window)\n",
        "    #magnitude, orientation = compute_magnitude_orientation(gx, gy)\n",
        "\n",
        "    # Create histograms for each 4x4 sub-block\n",
        "    descriptor = []\n",
        "    x_start = keypoint[2] - 8\n",
        "    y_start = keypoint[3] - 8\n",
        "    for o_x in range(x_start, x_start + 16, 4):\n",
        "      for o_y in range(y_start, y_start + 16, 4):\n",
        "        for s_x in range(o_x, o_x + 4):\n",
        "          for s_y in range(o_y, o_y + 4):\n",
        "               if s_x > 0 and s_y > 0 and s_x < image.shape[0] - 1 and s_y < image.shape[1] - 1:\n",
        "                    # Compute the gradient for each pixel (x, y)\n",
        "                    magnitude, orientation = compute_gradient(image, x, y)\n",
        "                    # Append the magnitude and orientation for later use\n",
        "\n",
        "                    #subtract dominant orientation for rotation independance\n",
        "                    orientation = (orientation - dominant_orientation)%360\n",
        "                    gradient_magnitudes.append(magnitude)\n",
        "                    gradient_orientations.append(orientation)\n",
        "                    desc_values = histogram(gradient_magnitudes, gradient_orientations, 8)\n",
        "                    for i in range(0, len(desc_values[0])):\n",
        "                      if(desc_values[0][i] > 0.2):\n",
        "                        descriptor.append(0.2)\n",
        "                      else:\n",
        "                        descriptor.append(desc_values[0][i])\n",
        "                    gradient_magnitudes.clear()\n",
        "                    gradient_orientations.clear()\n",
        "    # Calculate the L2 norm (Euclidean norm) of the descriptor vector\n",
        "    norm = np.linalg.norm(descriptor)\n",
        "    # If the norm is not zero, normalize the descriptor (avoid division by zero)\n",
        "    if norm != 0:\n",
        "        descriptor_vector /= norm\n",
        "    return descriptor\n",
        "\n"
      ],
      "metadata": {
        "id": "SOhrkWPH463d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}